{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('Training.csv', header=None)\n",
    "testdata = pd.read_csv('Testing.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,0]\n",
    "C = testdata.iloc[:,0]\n",
    "T = testdata.iloc[:,1:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 6.515e-04 6.515e-04 6.515e-04 1.968e-01 9.519e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.515e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 3.909e-03 3.909e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  6.515e-04 0.000e+00 0.000e+00 1.661e-01 1.661e-01 6.515e-04 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 1.224e-04 1.224e-04 1.224e-04 1.861e-02 9.989e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.224e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 2.448e-04 2.448e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.224e-04 0.000e+00 0.000e+00 3.122e-02 3.122e-02 1.224e-04 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 6.801e-04 6.801e-04 6.801e-04 1.510e-01 9.576e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.801e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 8.161e-03 8.161e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  6.801e-04 0.000e+00 0.000e+00 1.734e-01 1.734e-01 6.801e-04 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 7.321e-05 7.321e-05 7.321e-05 1.581e-02 9.997e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 7.321e-05 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.464e-04 1.464e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  7.321e-05 0.000e+00 0.000e+00 5.125e-04 1.867e-02 7.321e-05 0.000e+00\n",
      "  1.025e-05 7.321e-07 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 6.963e-05 6.963e-05 6.963e-05 1.434e-02 9.997e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.963e-05 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 6.267e-04 6.267e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  6.963e-05 0.000e+00 0.000e+00 6.267e-04 1.776e-02 6.963e-05 0.000e+00\n",
      "  7.659e-06 6.963e-07 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print(trainX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 1.834e-04 1.834e-04 1.834e-04 3.319e-02 9.994e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.834e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.467e-03 1.467e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.834e-04 0.000e+00 0.000e+00 1.650e-03 1.650e-03 1.834e-04 0.000e+00\n",
      "  2.017e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 1.844e-03 1.844e-03 1.844e-03 4.407e-01 8.961e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.844e-03 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.475e-02 1.475e-02 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.844e-03 0.000e+00 0.000e+00 3.503e-02 3.503e-02 1.844e-03 0.000e+00\n",
      "  9.219e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 7.363e-04 7.363e-04 7.363e-04 1.730e-01 9.844e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 7.363e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 5.890e-03 5.890e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  7.363e-04 0.000e+00 0.000e+00 2.135e-02 2.135e-02 7.363e-04 0.000e+00\n",
      "  2.209e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 7.375e-04 7.375e-04 7.375e-04 1.615e-01 9.860e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 7.375e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 4.425e-03 4.425e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  7.375e-04 0.000e+00 0.000e+00 2.876e-02 2.876e-02 7.375e-04 0.000e+00\n",
      "  2.212e-05 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 4.891e-04 4.891e-04 4.891e-04 1.061e-01 9.938e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.891e-04 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 2.934e-03 2.934e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  4.891e-04 0.000e+00 0.000e+00 2.396e-02 2.396e-02 4.891e-04 0.000e+00\n",
      "  9.781e-06 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "print(testT[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493715, 1, 41)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammedsara/anaconda3/envs/deeplearning3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/muhammedsara/anaconda3/envs/deeplearning3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(4, input_shape=(None, 41))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sequential_1', 'layers': [{'class_name': 'LSTM', 'config': {'name': 'lstm_1', 'trainable': True, 'batch_input_shape': (None, None, 41), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 4, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_1', 'trainable': True, 'activation': 'sigmoid'}}]}\n"
     ]
    }
   ],
   "source": [
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,input_dim=41))  # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "print(model.get_config())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammedsara/anaconda3/envs/deeplearning3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 493715 samples, validate on 306 samples\n",
      "Epoch 1/10\n",
      "493715/493715 [==============================] - 157s 318us/step - loss: 0.0608 - acc: 0.9785 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to checkpoint-01.hdf5\n",
      "Epoch 2/10\n",
      "493715/493715 [==============================] - 126s 256us/step - loss: 0.0290 - acc: 0.9882 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 1.00000\n",
      "Epoch 3/10\n",
      "493715/493715 [==============================] - 134s 271us/step - loss: 0.0258 - acc: 0.9897 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "Epoch 4/10\n",
      "493715/493715 [==============================] - 108s 219us/step - loss: 0.0236 - acc: 0.9905 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n",
      "Epoch 5/10\n",
      "493715/493715 [==============================] - 94s 190us/step - loss: 0.0214 - acc: 0.9920 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 1.00000\n",
      "Epoch 6/10\n",
      "493715/493715 [==============================] - 98s 199us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0186 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 1.00000\n",
      "Epoch 7/10\n",
      "493715/493715 [==============================] - 94s 191us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0154 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 1.00000\n",
      "Epoch 8/10\n",
      "493715/493715 [==============================] - 94s 191us/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.0130 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 1.00000\n",
      "Epoch 9/10\n",
      "493715/493715 [==============================] - 102s 207us/step - loss: 0.0158 - acc: 0.9946 - val_loss: 0.0138 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 1.00000\n",
      "Epoch 10/10\n",
      "493715/493715 [==============================] - 108s 219us/step - loss: 0.0152 - acc: 0.9947 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "306/306 [==============================] - 0s 59us/step\n",
      "\n",
      "Loss: 0.01, Accuracy: 99.67%\n"
     ]
    }
   ],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/training_set_iranalysis.csv',separator=',', append=False)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.save(\"results/lstm1layer_model.hdf5\")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "np.savetxt('lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
