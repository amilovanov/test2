{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T21:00:24.035408Z",
     "start_time": "2019-05-14T21:00:22.074706Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error\n",
    "                             ,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T21:00:25.331873Z",
     "start_time": "2019-05-14T21:00:24.040218Z"
    }
   },
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('/Users/yusufsatilmis/Desktop/Bilgisayar_Aglari/Training.csv', header=None)\n",
    "testdata = pd.read_csv('/Users/yusufsatilmis/Desktop/Bilgisayar_Aglari/Testing.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T21:00:25.768980Z",
     "start_time": "2019-05-14T21:00:25.338029Z"
    }
   },
   "outputs": [],
   "source": [
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,0]\n",
    "C = testdata.iloc[:,0]\n",
    "T = testdata.iloc[:,1:42]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T21:00:26.055618Z",
     "start_time": "2019-05-14T21:00:25.775473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/deeplearning2/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(41, 1))`\n",
      "  import sys\n",
      "/anaconda2/envs/deeplearning2/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(MaxPooling1D(pool_length=(2)))\n",
    "cnn.add(LSTM(lstm_output_size))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:04:33.362146Z",
     "start_time": "2019-05-14T21:00:26.061289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/deeplearning2/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 493715 samples, validate on 306 samples\n",
      "Epoch 1/10\n",
      "493715/493715 [==============================] - 717s 1ms/step - loss: 0.0297 - acc: 0.9900 - val_loss: 0.0076 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99673, saving model to results/cnn1results/checkpoint-01.hdf5\n",
      "Epoch 2/10\n",
      "493715/493715 [==============================] - 684s 1ms/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0180 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99673\n",
      "Epoch 3/10\n",
      "493715/493715 [==============================] - 684s 1ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0201 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99673\n",
      "Epoch 4/10\n",
      "493715/493715 [==============================] - 686s 1ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0199 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99673\n",
      "Epoch 5/10\n",
      "493715/493715 [==============================] - 696s 1ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0209 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99673\n",
      "Epoch 6/10\n",
      "493715/493715 [==============================] - 701s 1ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0231 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99673\n",
      "Epoch 7/10\n",
      "493715/493715 [==============================] - 709s 1ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0131 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99673\n",
      "Epoch 8/10\n",
      "493715/493715 [==============================] - 834s 2ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0172 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99673\n",
      "Epoch 9/10\n",
      "493715/493715 [==============================] - 859s 2ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99673 to 1.00000, saving model to results/cnn1results/checkpoint-09.hdf5\n",
      "Epoch 10/10\n",
      "493715/493715 [==============================] - 875s 2ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0043 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/cnn1results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('results/cnn1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
    "cnn.fit(X_train, y_train, nb_epoch=10,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "cnn.save(\"results/cnn1results/cnn_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.load_weights(\"results/cnn1results/checkpoint-947.hdf5\")\n",
    "\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:46:13.843938Z",
     "start_time": "2019-05-14T23:46:13.672039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 513us/step\n",
      "\n",
      "Loss: 0.00, Accuracy: 99.67%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:47:21.748961Z",
     "start_time": "2019-05-14T23:47:21.608422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.996732\n",
      "racall\n",
      "0.000000\n",
      "precision\n",
      "0.000000\n",
      "f1score\n",
      "0.000000\n",
      "==============================================\n",
      "[[305   1]\n",
      " [  0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict_classes(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "np.savetxt('results/expected1.txt', y_test, fmt='%01d')\n",
    "np.savetxt('results/predicted1.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" %accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" %recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" %precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"==============================================\")\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
